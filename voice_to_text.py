# meta developer: @Lucky_modules
# requires: SpeechRecognition
import os
import asyncio
import speech_recognition as sr
from pydub import AudioSegment
from .. import loader, utils
import math

try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False

@loader.tds
class VoiceToTextMod(loader.Module):
    """–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞—á—à–∏—Ñ—Ä–æ–≤–∫–∏ –ì–°"""
    strings = {
        "name": "VoiceToText",
        "processing": "üîä –†–∞—Å–ø–æ–∑–Ω–∞—é –ì–°...",
        "no_voice": "‚ùå –≠—Ç–æ –Ω–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
        "download_error": "‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ",
        "convert_error": "‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ",
        "recognition_error": "‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {}",
        "result": "üîä –Ø —Ä–∞—Å–ø–æ–∑–Ω–∞–ª:\n\n<blockquote>{}</blockquote>",
        "timeout_error": "‚è∞ –Ø —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–ª –±–æ–ª—å—à–µ 1 –º–∏–Ω—É—Ç—ã (—ç—Ç–æ —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ). –í–æ—Ç —á—Ç–æ —è —É—Å–ø–µ–ª —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å:\n\n<blockquote>{}</blockquote>",
        "chat_enabled": "‚úÖ –ê–≤—Ç–æ—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ –≤–∫–ª—é—á–µ–Ω–æ –≤ —ç—Ç–æ–º —á–∞—Ç–µ",
        "chat_disabled": "‚ùå –ê–≤—Ç–æ—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ –æ—Ç–∫–ª—é—á–µ–Ω–æ –≤ —ç—Ç–æ–º —á–∞—Ç–µ",
        "chat_status": "üîÑ –ê–≤—Ç–æ—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞: {}",
        "whisper_not_installed": "‚ö†Ô∏è –î–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã —É—Å—Ç–∞–Ω–æ–≤–∏ Whisper: pip install openai-whisper\n–°–µ–π—á–∞—Å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–µ–¥–ª–µ–Ω–Ω–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ Google Speech Recognition",
    }

    def __init__(self):
        self.db = None
        self.recognizer = sr.Recognizer()
        self.whisper_model = None

    async def client_ready(self, client, db):
        self.client = client
        self.db = db
        if not self.db.get("VoiceToText", "chats"):
            self.db.set("VoiceToText", "chats", {})
        
        if not WHISPER_AVAILABLE:
            print(self.strings["whisper_not_installed"])
        
        if WHISPER_AVAILABLE and not self.whisper_model:
            try:
                self.whisper_model = whisper.load_model("tiny")
            except:
                pass

    async def vttcmd(self, message):
        """–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        if not message.is_reply:
            await utils.answer(message, "‚ùå –û—Ç–≤–µ—Ç—å –Ω–∞ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ!")
            return
        reply = await message.get_reply_message()
        await self.process_voice_message_with_timeout(message, reply)

    async def vttchatcmd(self, message):
        """–í–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤ —á–∞—Ç–µ"""
        chat_id = str(message.chat_id)
        chats = self.db.get("VoiceToText", "chats", {})
        current_status = chats.get(chat_id, False)
        new_status = not current_status
        chats[chat_id] = new_status
        self.db.set("VoiceToText", "chats", chats)
        status_text = "–≤–∫–ª—é—á–µ–Ω–æ" if new_status else "–æ—Ç–∫–ª—é—á–µ–Ω–æ"
        await utils.answer(message, f"‚úÖ –ê–≤—Ç–æ—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ {status_text} –≤ —ç—Ç–æ–º —á–∞—Ç–µ")

    async def process_voice_message_with_timeout(self, processing_msg, voice_message):
        processing_active = {"active": True, "partial_text": ""}
        
        async def timeout_handler():
            await asyncio.sleep(60.0)
            if processing_active["active"]:
                processing_active["active"] = False
                partial_text = processing_active["partial_text"].strip()
                timeout_text = partial_text if partial_text else "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ"
                
                try:
                    await utils.answer(
                        processing_msg,
                        self.strings["timeout_error"].format(timeout_text),
                        reply_to=voice_message.id
                    )
                except:
                    try:
                        await processing_msg.delete()
                        await voice_message.reply(self.strings["timeout_error"].format(timeout_text))
                    except:
                        pass
        
        timeout_task = asyncio.create_task(timeout_handler())
        
        try:
            await self.process_voice_message_streaming(processing_msg, voice_message, processing_active)
            processing_active["active"] = False
            timeout_task.cancel()
        except Exception as e:
            processing_active["active"] = False
            timeout_task.cancel()
            raise e

    async def process_voice_message_streaming(self, processing_msg, voice_message, processing_active):
        try:
            if not any([voice_message.voice, voice_message.audio]):
                await utils.answer(processing_msg, self.strings["no_voice"])
                return

            await utils.answer(processing_msg, self.strings["processing"])

            file = await voice_message.download_media()
            if not file:
                await utils.answer(processing_msg, self.strings["download_error"])
                return

            wav_file = await self.convert_to_wav(file)
            os.remove(file)

            audio_segments = await self.split_audio_into_chunks(wav_file, chunk_duration=5)
            
            full_text = ""
            last_update_time = asyncio.get_event_loop().time()
            chunks_processed = 0
            
            for i, chunk_file in enumerate(audio_segments, 1):
                if not processing_active["active"]:
                    for remaining_chunk in audio_segments[i-1:]:
                        if os.path.exists(remaining_chunk):
                            os.remove(remaining_chunk)
                    break
                    
                try:
                    chunk_text = await self.recognize_speech_chunk(chunk_file)
                    
                    if chunk_text.strip() and not chunk_text.startswith("‚ùå"):
                        full_text += chunk_text + " "
                        processing_active["partial_text"] = full_text
                    
                    os.remove(chunk_file)
                    chunks_processed += 1
                    
                    current_time = asyncio.get_event_loop().time()
                    should_update = (current_time - last_update_time >= 5.0) or (chunks_processed == 1 and full_text.strip())
                    
                    if should_update and full_text.strip() and processing_active["active"]:
                        try:
                            await utils.answer(
                                processing_msg,
                                f"üîä –Ø —Ä–∞—Å–ø–æ–∑–Ω–∞–ª<blockquote>{full_text.strip()}</blockquote>"
                            )
                            last_update_time = current_time
                        except:
                            pass
                    
                except Exception as e:
                    if os.path.exists(chunk_file):
                        os.remove(chunk_file)
                    continue

            os.remove(wav_file)
            
            if processing_active["active"]:
                final_text = full_text.strip() or "‚ùå –†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞"
                
                try:
                    await utils.answer(
                        processing_msg,
                        self.strings["result"].format(final_text),
                        reply_to=voice_message.id
                    )
                except:
                    try:
                        await processing_msg.delete()
                        await voice_message.reply(self.strings["result"].format(final_text))
                    except:
                        pass
                
        except Exception as e:
            if processing_active["active"]:
                try:
                    await utils.answer(processing_msg, self.strings["recognition_error"].format(str(e)))
                except:
                    try:
                        await processing_msg.delete()
                        await voice_message.reply(self.strings["recognition_error"].format(str(e)))
                    except:
                        pass

    async def split_audio_into_chunks(self, wav_file, chunk_duration=5):
        try:
            audio = AudioSegment.from_wav(wav_file)
            chunk_length_ms = chunk_duration * 1000
            chunks = []
            
            for i in range(0, len(audio), chunk_length_ms):
                chunk = audio[i:i + chunk_length_ms]
                chunk_file = f"{wav_file}_chunk_{i//chunk_length_ms}.wav"
                chunk.export(chunk_file, format="wav")
                chunks.append(chunk_file)
            
            return chunks
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è –∞—É–¥–∏–æ: {str(e)}")

    async def convert_to_wav(self, input_file):
        try:
            output_file = input_file + ".wav"
            audio = AudioSegment.from_file(input_file)
            audio = audio.set_frame_rate(16000).set_channels(1)
            audio.export(output_file, format="wav")
            return output_file
        except Exception as e:
            raise Exception(self.strings["convert_error"] + ": " + str(e))

    async def recognize_speech_chunk(self, wav_file):
        try:
            if WHISPER_AVAILABLE and self.whisper_model:
                result = self.whisper_model.transcribe(
                    wav_file, 
                    language="ru",
                    fp16=False,
                    verbose=False
                )
                return result.get("text", "").strip() or ""
            else:
                with sr.AudioFile(wav_file) as source:
                    self.recognizer.energy_threshold = 300
                    self.recognizer.dynamic_energy_threshold = False
                    audio_data = self.recognizer.record(source)
                    text = self.recognizer.recognize_google(audio_data, language="ru-RU")
                    return text
        except sr.UnknownValueError:
            return ""
        except sr.RequestError as e:
            return f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞: {str(e)}"
        except Exception as e:
            return f"‚ùå –û—à–∏–±–∫–∞: {str(e)}"

    async def recognize_speech(self, wav_file):
        return await self.recognize_speech_chunk(wav_file)

    async def watcher(self, message):
        chat_id = str(message.chat_id)
        if not self.db.get("VoiceToText", "chats", {}).get(chat_id, False):
            return
        if any([message.voice, message.audio]):
            try:
                processing_msg = await message.reply(self.strings["processing"])
                await self.process_voice_message_with_timeout(processing_msg, message)
            except Exception as e:
                await message.reply(self.strings["recognition_error"].format(str(e)))
